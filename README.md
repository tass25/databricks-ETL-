# From GitHub Parquet to Delta Lake Gold 🚀✨

Welcome to my **first full-fledged end-to-end Data Engineering masterpiece** on **Azure + Databricks**
This project takes raw Parquet files from GitHub and transforms them into **analytics-ready Gold tables**, following the legendary **Bronze → Silver → Gold architecture**.  

---

## 🌟 Why This Project Rocks

This isn’t just another ETL pipeline — it’s a **battle-tested, production-ready workflow** demonstrating:

- Ingestion of raw data ✅  
- Advanced transformations, joins, and aggregations 🧹🔗  
- Automated **quality checks** and schema validation ✅  
- **Star Schema modeling** for Gold tables ⭐  
- **Security first**: Azure AD & Key Vault 🔒  
- Full **automation** in Databricks notebooks 🤖  

In short: **from chaos to clean, from raw to gold**.  

---

## 🛠 Tech Stack & Tools

| Layer | Technology / Tool |
|-------|-----------------|
| Cloud | Azure Data Lake Gen2, Azure AD, Key Vault |
| Data Platform | Databricks, Delta Live Tables |
| Language | Python, PySpark |
| Architecture | Bronze → Silver → Gold |

---

## ⚡ Pipeline Highlights

### Bronze Layer 🥉
- Raw Parquet ingestion from GitHub  
- Minimal transformations — keep it raw & honest  

### Silver Layer 🥈
- PySpark ETL: cleaning, deduplication, joins, aggregations  
- Data quality checks with Delta Live Tables rules  

### Gold Layer 🥇
- Analytical-ready tables following **Star Schema design**  
- Fully automated transformations for reporting-ready datasets  

---

## 📈 Architecture

![Pipeline Architecture](Azure%20Data%20Lake%20Gen2.png)
*Elegant, automated, secure, and ready for analytics.*  

---

## 🚀 Challenges & Learnings

- Debugging Spark jobs on Databricks for the first time was an adventure ⚡  
- Exploring **Azure** from scratch pushed me to learn **cloud, security, and automation** simultaneously  
- Couldn’t implement **Synapse + Power BI** due to credit limits, but the **foundation is solid as gold**  

> 💡 *Lesson learned*: You don’t need billions of rows to master Data Engineering — just **discipline, curiosity, and consistency**.  

---

## 📝 Next Steps

- Integrate **Synapse Analytics** for reporting  
- Build **Power BI dashboards** on top of Gold tables  
- Optimize Spark jobs for larger datasets  
- Expand pipeline to multiple data sources  

---

## 💡 Takeaway

This project is a perfect **hands-on playground** for anyone who wants to:

- Learn **modern Data Engineering practices** on Azure & Databricks  
- Master **Delta Lake and ETL pipelines**  
- Understand **automated workflows, data quality, and schema modeling**
